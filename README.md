# Chapter-11-Traininng-Neural-Networks
This is a summary and application of techniques learned from the  "Hands on Machine Learning with Scikit Learn and Tensorflow" book by Geron Aurelien

The work is done on a Juypter Notebook and the content is specificatlly based on how one can train Neural Networks effectivly and how to avoid the issues that one can face when training Neural Networks

## The following was covered:

### 1. How to deal with the Vanishing Gradient Problem
-----------------------------------------------------------------------

Vasnishing Gradient is defined and further discussion on how it occurs
Techniques are discussed that can be used to combat vanishing gradients during training. 


### 2. Transfer Learning
-----------------------------------------------------------------------

This techniques is covered in-depth, discussing when it should be used and how you can apply transfer learning in a project. In addtion, some of the pitfalls are highlighted and the best practices to avoid these pitfalls.

### 3. Optimizers
-----------------------------------------------------------------------

In this section, the best optimizers are covered. Well not the best, but rather the different types of optimizers that are available. In addition, their different strengths and weaknesses are discussed as well a comparison between different optimizers. Finally, learning rate scheduling is covered as, finding the right learning rate often occurs as a common tasks when training neural nets.

The book is an awesome resource to have. I am constantly going back to it and reviewing techniques, that I know and learning new techniques that I do not know.
